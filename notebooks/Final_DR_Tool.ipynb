{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "1C7iHHkDVRh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "sWVNM5NlVbkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RUN 1"
      ],
      "metadata": {
        "id": "44ngzW8xaA8r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frT1ruVaUuoE"
      },
      "outputs": [],
      "source": [
        "# ----- STEP 0: Mount Google Drive (if not already mounted) -----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----- STEP 1: Import Libraries and Set Mixed Precision Policy -----\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB3  # Or change to EfficientNetB4/DenseNet121 as desired\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Use the new mixed precision API\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# ----- STEP 2: Define Directory Paths and Load CSVs -----\n",
        "# Update these paths to match your Google Drive structure\n",
        "train_img_dir = '/content/drive/My Drive/aptos2019-blindness-detection/train_images/'\n",
        "test_img_dir  = '/content/drive/My Drive/aptos2019-blindness-detection/test_images/'\n",
        "\n",
        "train_csv_path = '/content/train.csv'\n",
        "test_csv_path  = '/content/test.csv'\n",
        "\n",
        "# Load CSV files\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df  = pd.read_csv(test_csv_path)\n",
        "\n",
        "\n",
        "# Convert 'diagnosis' to string (required for categorical generators)\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "\n",
        "# Create a filename column by appending the '.png' extension to id_code\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "test_df['filename']  = test_df['id_code'] + '.png'\n",
        "\n",
        "\n",
        "\n",
        "# ----- STEP 3: Split Data into Training and Validation Sets -----\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "# Ensure filename and diagnosis columns are properly set\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "val_df['filename']   = val_df['id_code'] + '.png'\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "val_df['diagnosis']   = val_df['diagnosis'].astype(str)\n",
        "\n",
        "# ----- STEP 4: Define Image Size and Create Data Generators with Enhanced Augmentation -----\n",
        "# Image size is optimized to 380x380 for EfficientNetB3; adjust if needed\n",
        "IMAGE_SIZE = (380, 380)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,               # Smaller rotation for medical images\n",
        "    brightness_range=[0.8, 1.2],       # Adjust brightness/contrast relevant for retinal scans\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='constant',\n",
        "    cval=0                         # Black background for retinal images\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=train_img_dir,\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    validate_filenames=True\n",
        ")\n",
        "\n",
        "# Note: For validation, if the images are in the same folder as training images, use train_img_dir.\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=train_img_dir,\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# ----- STEP 5: Set Up Callbacks (Learning Rate Scheduler, EarlyStopping, and ModelCheckpoint) -----\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model.h5', save_best_only=True),\n",
        "    reduce_lr\n",
        "]\n",
        "\n",
        "# ----- STEP 6: Build the Model Using a Pretrained Base (EfficientNetB3) and Custom Top Layers -----\n",
        "# Load base model without top layers, with pretrained ImageNet weights\n",
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "base_model.trainable = False  # Freeze the base model initially\n",
        "\n",
        "# Add custom top layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)  # Batch Normalization re-calibration\n",
        "# The final layer: note 'dtype' is set to float32 to counter mixed precision output issues\n",
        "output = Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Show model architecture\n",
        "model.summary()\n",
        "\n",
        "# ----- STEP 7: Compile the Model with Additional Evaluation Metrics -----\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',  # Optionally, use a custom weighted or focal loss for imbalanced classes\n",
        "    metrics=['accuracy', AUC(), Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ----- (Optional) STEP 8: Progressive Unfreezing for Fine-Tuning -----\n",
        "# After initial training, you can gradually unfreeze layers for controlled fine-tuning.\n",
        "# Uncomment the following block after initial training and recompile with a lower learning rate.\n",
        "'''\n",
        "for layer in base_model.layers[-20:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', AUC(), Precision(), Recall()]\n",
        ")\n",
        "'''\n",
        "\n",
        "# ----- STEP 9: Train the Model -----\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,  # Adjust epochs as needed\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# ----- STEP 10: Implement Grad-CAM for Explainability -----\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    \"\"\"\n",
        "    Generates a Grad-CAM heatmap for a given image and model.\n",
        "    \"\"\"\n",
        "    # Create a model that maps the input image to the activations of the last conv layer and predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Compute the gradient of the predicted class (or the provided pred_index) with respect to the activations\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "\n",
        "    # Compute the gradients of the target class with respect to the convolutional layer outputs\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Multiply each channel in the feature map array by \"how important this channel is\" with regard to the target class\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Normalize the heatmap between 0 and 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    \"\"\"\n",
        "    Overlays the Grad-CAM heatmap on the original image.\n",
        "    \"\"\"\n",
        "    # Load the original image\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize heatmap to match image dimensions\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Apply a color map to the heatmap\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    # Superimpose the heatmap on the image\n",
        "    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# ----- STEP 11: Demonstrate Grad-CAM on a Sample Image -----\n",
        "# Choose a sample image from the training directory\n",
        "sample_img_path = os.path.join(train_img_dir, train_df['filename'].iloc[0])\n",
        "# Preprocess the image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img = image.load_img(sample_img_path, target_size=IMAGE_SIZE)\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Replace 'top_conv' with the actual name of your last convolutional layer in EfficientNetB3\n",
        "# You can find the name by inspecting model.summary()\n",
        "last_conv_layer_name = None\n",
        "for layer in base_model.layers[::-1]:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "if last_conv_layer_name is None:\n",
        "    raise ValueError(\"No convolutional layer found in the base model.\")\n",
        "\n",
        "# Generate the Grad-CAM heatmap\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "# Display the heatmap overlaid on the original image\n",
        "display_gradcam(sample_img_path, heatmap)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RUN 2"
      ],
      "metadata": {
        "id": "deAinbyKaFHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- STEP 0: Mount Google Drive -----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----- STEP 1: Import Libraries and Set Mixed Precision Policy -----\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB4  # Using EfficientNetB4 for higher capacity\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "\n",
        "# Enable mixed precision training for speed on compatible GPUs\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# ----- STEP 2: Define Directory Paths and Load CSVs -----\n",
        "train_img_dir = '/content/drive/My Drive/aptos2019-blindness-detection/train_images/'\n",
        "test_img_dir  = '/content/drive/My Drive/aptos2019-blindness-detection/test_images/'\n",
        "train_csv_path = '/content/drive/My Drive/aptos2019-blindness-detection/train.csv'\n",
        "test_csv_path  = '/content/drive/My Drive/aptos2019-blindness-detection/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df  = pd.read_csv(test_csv_path)\n",
        "\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "test_df['filename']  = test_df['id_code'] + '.png'\n",
        "\n",
        "# ----- STEP 3: Split Data into Training and Validation Sets -----\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "val_df['filename']   = val_df['id_code'] + '.png'\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "val_df['diagnosis']   = val_df['diagnosis'].astype(str)\n",
        "\n",
        "# ----- STEP 4: Define Image Size and Create Data Generators -----\n",
        "IMAGE_SIZE = (380, 380)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='constant',\n",
        "    cval=0\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=train_img_dir,\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    validate_filenames=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=train_img_dir,  # Assuming validation images are in the same folder\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# ----- STEP 5: Set Up Callbacks -----\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model.h5', save_best_only=True),\n",
        "    reduce_lr\n",
        "]\n",
        "\n",
        "# ----- STEP 6: Build the Model Using EfficientNetB4 and Unfreeze All Layers -----\n",
        "base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "base_model.trainable = True  # Unfreeze all layers for full fine-tuning\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.summary()\n",
        "\n",
        "# ----- STEP 7: Compile the Model with a Lower Learning Rate for Fine-Tuning -----\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),  # Lower LR for full fine-tuning\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', AUC(), Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ----- STEP 8: Train the Model (Full Fine-Tuning) -----\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,  # Increase epochs as needed\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# ----- STEP 9: Grad-CAM for Explainability -----\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# ----- STEP 10: Demonstrate Grad-CAM on a Sample Image -----\n",
        "sample_img_path = os.path.join(train_img_dir, train_df['filename'].iloc[0])\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img = image.load_img(sample_img_path, target_size=IMAGE_SIZE)\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "last_conv_layer_name = None\n",
        "for layer in base_model.layers[::-1]:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "if last_conv_layer_name is None:\n",
        "    raise ValueError(\"No convolutional layer found in the base model.\")\n",
        "\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "display_gradcam(sample_img_path, heatmap)\n"
      ],
      "metadata": {
        "id": "tLtCx26hCLRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RUN 3"
      ],
      "metadata": {
        "id": "p_uzk-TweqIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- STEP 0: Mount Google Drive -----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----- STEP 1: Import Libraries and Set Mixed Precision Policy -----\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# ----- STEP 2: Define Directory Paths and Load CSVs -----\n",
        "train_img_dir = '/content/drive/My Drive/aptos2019-blindness-detection/train_images/'\n",
        "test_img_dir  = '/content/drive/My Drive/aptos2019-blindness-detection/test_images/'\n",
        "train_csv_path = '/content/drive/My Drive/aptos2019-blindness-detection/train.csv'\n",
        "test_csv_path  = '/content/drive/My Drive/aptos2019-blindness-detection/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df  = pd.read_csv(test_csv_path)\n",
        "\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "test_df['filename']  = test_df['id_code'] + '.png'\n",
        "\n",
        "# ----- STEP 3: Split Data into Training and Validation Sets -----\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "val_df['filename']   = val_df['id_code'] + '.png'\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "val_df['diagnosis']   = val_df['diagnosis'].astype(str)\n",
        "\n",
        "# ----- STEP 4: Define Image Size and Create Data Generators -----\n",
        "IMAGE_SIZE = (380, 380)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='constant',\n",
        "    cval=0\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=train_img_dir,\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    validate_filenames=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=train_img_dir,  # Assuming validation images are in the same folder\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# ----- STEP 5: Set Up Callbacks with ModelCheckpoint -----\n",
        "checkpoint_filepath = '/content/drive/My Drive/aptos2019-blindness-detection/best_model.keras'\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    save_weights_only=False\n",
        ")\n",
        "early_stopping_callback = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "callbacks = [checkpoint_callback, reduce_lr, early_stopping_callback]\n",
        "\n",
        "# ----- STEP 6: Build the Model Using EfficientNetB4 and Unfreeze All Layers -----\n",
        "base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "base_model.trainable = True  # Unfreeze all layers for full fine-tuning\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.summary()\n",
        "\n",
        "# ----- STEP 7: Compile the Model with a Lower Learning Rate for Fine-Tuning -----\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', AUC(), Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ----- STEP 8: Train the Model (Full Fine-Tuning) -----\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# ----- STEP 9: Grad-CAM for Explainability -----\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    max_val = tf.math.reduce_max(heatmap)\n",
        "    if max_val == 0:\n",
        "        heatmap = tf.zeros_like(heatmap)\n",
        "    else:\n",
        "        heatmap = tf.maximum(heatmap, 0) / max_val\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# ----- STEP 10: Demonstrate Grad-CAM on a Sample Image -----\n",
        "sample_img_path = os.path.join(train_img_dir, train_df['filename'].iloc[0])\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img = image.load_img(sample_img_path, target_size=IMAGE_SIZE)\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "last_conv_layer_name = None\n",
        "for layer in base_model.layers[::-1]:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "if last_conv_layer_name is None:\n",
        "    raise ValueError(\"No convolutional layer found in the base model.\")\n",
        "\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "display_gradcam(sample_img_path, heatmap)\n"
      ],
      "metadata": {
        "id": "lQaZokajWycn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----- STEP 0: Mount Google Drive -----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----- STEP 1: Import Libraries and Set Mixed Precision Policy -----\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# ----- STEP 2: Define Directory Paths and Load CSVs -----\n",
        "train_img_dir = '/content/drive/My Drive/aptos2019-blindness-detection/train_images/'\n",
        "test_img_dir  = '/content/drive/My Drive/aptos2019-blindness-detection/test_images/'\n",
        "train_csv_path = '/content/drive/My Drive/aptos2019-blindness-detection/train.csv'\n",
        "test_csv_path  = '/content/drive/My Drive/aptos2019-blindness-detection/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df  = pd.read_csv(test_csv_path)\n",
        "\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "test_df['filename']  = test_df['id_code'] + '.png'\n",
        "\n",
        "# ----- STEP 3: Split Data into Training and Validation Sets -----\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "val_df['filename']   = val_df['id_code'] + '.png'\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "val_df['diagnosis']   = val_df['diagnosis'].astype(str)\n",
        "\n",
        "# ----- STEP 4: Define Image Size and Create Data Generators -----\n",
        "IMAGE_SIZE = (380, 380)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='constant',\n",
        "    cval=0\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=train_img_dir,\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    validate_filenames=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=train_img_dir,  # Assuming validation images are in the same folder\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# ----- STEP 5: Set Up Callbacks with ModelCheckpoint -----\n",
        "checkpoint_filepath = '/content/drive/My Drive/aptos2019-blindness-detection/best_model.keras'\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    save_weights_only=False\n",
        ")\n",
        "early_stopping_callback = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "callbacks = [checkpoint_callback, reduce_lr, early_stopping_callback]\n",
        "\n",
        "# ----- STEP 6: Build the Model Using EfficientNetB4 -----\n",
        "# Initially, freeze the base model for Phase 1 training.\n",
        "base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "base_model.trainable = False  # Freeze all layers initially\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.summary()\n",
        "\n",
        "# ----- STEP 7: Compile the Model for Phase 1 (Frozen Base) -----\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', AUC(), Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ----- STEP 8: Train the Model (Phase 1) -----\n",
        "print(\"Starting Phase 1 Training (Frozen Base)...\")\n",
        "history_phase1 = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,  # Train initially for 10 epochs\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# ----- STEP 9: Progressive Unfreezing (Phase 2) -----\n",
        "# Unfreeze the last 30 layers of the base model for fine-tuning.\n",
        "for layer in base_model.layers[-30:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile the model with a lower learning rate for fine-tuning.\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', AUC(), Precision(), Recall()]\n",
        ")\n",
        "\n",
        "print(\"Starting Phase 2 Training (Unfrozen Last 30 Layers)...\")\n",
        "history_phase2 = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,  # Fine-tune for an additional 10 epochs\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# ----- STEP 10: Grad-CAM for Explainability -----\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    max_val = tf.math.reduce_max(heatmap)\n",
        "    if max_val == 0:\n",
        "        heatmap = tf.zeros_like(heatmap)\n",
        "    else:\n",
        "        heatmap = tf.maximum(heatmap, 0) / max_val\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# ----- STEP 11: Demonstrate Grad-CAM on a Sample Image -----\n",
        "sample_img_path = os.path.join(train_img_dir, train_df['filename'].iloc[0])\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img = image.load_img(sample_img_path, target_size=IMAGE_SIZE)\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "last_conv_layer_name = None\n",
        "for layer in base_model.layers[::-1]:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "if last_conv_layer_name is None:\n",
        "    raise ValueError(\"No convolutional layer found in the base model.\")\n",
        "\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "display_gradcam(sample_img_path, heatmap)\n"
      ],
      "metadata": {
        "id": "0zRbpsvcewkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runtime got interrupted\n"
      ],
      "metadata": {
        "id": "Cpb-CQPb2ptj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rOlJXX2i2ubD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the last saved checkpoint\n",
        "model = load_model('/content/drive/My Drive/aptos2019-blindness-detection/best_model.keras')\n",
        "\n",
        "# Resume training from the current state (optionally set initial_epoch if you want to log from where you left off)\n",
        "history_resume = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,  # set additional epochs\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks,\n",
        "    initial_epoch=8  # if you want to indicate that 8 epochs have already been run\n",
        ")\n"
      ],
      "metadata": {
        "id": "cAo7Tt8Q1KzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################\n",
        "# Phase 2: Progressive Fine-Tuning (Unfreeze Layers)\n",
        "#####################################################\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load your best checkpoint from Phase 1\n",
        "model = load_model('/content/drive/My Drive/aptos2019-blindness-detection/best_model.keras')\n",
        "\n",
        "# Attempt to locate the base model (EfficientNet) within the loaded model.\n",
        "base_model = None\n",
        "for layer in model.layers:\n",
        "    if \"efficientnet\" in layer.name.lower():\n",
        "        base_model = layer\n",
        "        break\n",
        "\n",
        "if base_model is None:\n",
        "    print(\"Warning: Base model not found in model layers. Unfreezing the entire model.\")\n",
        "    # Unfreeze the entire model as a fallback.\n",
        "    model.trainable = True\n",
        "else:\n",
        "    # Unfreeze only the last 20 layers of the base model.\n",
        "    for layer in base_model.layers[-20:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "# Recompile the model with a lower learning rate for fine-tuning.\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', 'AUC', 'Precision', 'Recall']\n",
        ")\n",
        "\n",
        "# Continue training (fine-tuning) the model.\n",
        "history_finetune = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,  # Adjust the number of epochs for fine-tuning as needed.\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint_callback, reduce_lr, early_stopping_callback]\n",
        ")\n",
        "\n",
        "#####################################################\n",
        "# End of Phase 2 Fine-Tuning Script\n",
        "#####################################################\n"
      ],
      "metadata": {
        "id": "k-4e60am7v6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model('/content/drive/My Drive/aptos2019-blindness-detection/best_model.keras')\n",
        "\n",
        "# Evaluate the model on your validation set\n",
        "val_results = model.evaluate(val_generator, verbose=1)\n",
        "print(\"Validation Results:\", val_results)\n"
      ],
      "metadata": {
        "id": "BWirzRaQOTuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assume 'history' is your training history dictionary (e.g., history.history)\n",
        "# If you saved it to a pickle file, you can load it:\n",
        "# import pickle\n",
        "# with open('training_history.pkl', 'rb') as f:\n",
        "#     history = pickle.load(f)\n",
        "\n",
        "def extract_best_metrics(history):\n",
        "    # Convert lists to numpy arrays for easier processing.\n",
        "    acc = np.array(history.get('accuracy', []))\n",
        "    val_acc = np.array(history.get('val_accuracy', []))\n",
        "    loss = np.array(history.get('loss', []))\n",
        "    val_loss = np.array(history.get('val_loss', []))\n",
        "    auc = np.array(history.get('AUC', []))\n",
        "    val_auc = np.array(history.get('val_AUC', []))\n",
        "    precision = np.array(history.get('Precision', []))\n",
        "    val_precision = np.array(history.get('val_Precision', []))\n",
        "    recall = np.array(history.get('Recall', []))\n",
        "    val_recall = np.array(history.get('val_Recall', []))\n",
        "\n",
        "    # Find the best epoch based on validation accuracy.\n",
        "    best_epoch = np.argmax(val_acc)\n",
        "\n",
        "    metrics = {\n",
        "        'best_epoch': int(best_epoch + 1),\n",
        "        'train_accuracy': acc[best_epoch] if acc.size > 0 else None,\n",
        "        'val_accuracy': val_acc[best_epoch] if val_acc.size > 0 else None,\n",
        "        'train_loss': loss[best_epoch] if loss.size > 0 else None,\n",
        "        'val_loss': val_loss[best_epoch] if val_loss.size > 0 else None,\n",
        "        'train_auc': auc[best_epoch] if auc.size > 0 else None,\n",
        "        'val_auc': val_auc[best_epoch] if val_auc.size > 0 else None,\n",
        "        'train_precision': precision[best_epoch] if precision.size > 0 else None,\n",
        "        'val_precision': val_precision[best_epoch] if val_precision.size > 0 else None,\n",
        "        'train_recall': recall[best_epoch] if recall.size > 0 else None,\n",
        "        'val_recall': val_recall[best_epoch] if val_recall.size > 0 else None,\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "# Extract and print the best metrics.\n",
        "best_metrics = extract_best_metrics(history)\n",
        "print(\"Best Metrics from Training History:\")\n",
        "for k, v in best_metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\" if isinstance(v, float) else f\"{k}: {v}\")\n",
        "\n",
        "# Check if the best validation accuracy is above 90%\n",
        "if best_metrics.get('val_accuracy', 0) >= 0.90:\n",
        "    print(\"Validation accuracy is above 90%.\")\n",
        "else:\n",
        "    print(\"Validation accuracy is below 90%. Further fine-tuning is recommended.\")\n"
      ],
      "metadata": {
        "id": "PV-z6l4vLHZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################\n",
        "# Full Integrated Script with Class Weights & Fine-Tuning\n",
        "#####################################################\n",
        "\n",
        "# ----- STEP 0: Mount Google Drive -----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----- STEP 1: Import Libraries and Set Mixed Precision Policy -----\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# ----- STEP 2: Define Directory Paths and Load CSVs -----\n",
        "train_img_dir = '/content/drive/My Drive/aptos2019-blindness-detection/train_images/'\n",
        "test_img_dir  = '/content/drive/My Drive/aptos2019-blindness-detection/test_images/'\n",
        "train_csv_path = '/content/drive/My Drive/aptos2019-blindness-detection/train.csv'\n",
        "test_csv_path  = '/content/drive/My Drive/aptos2019-blindness-detection/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df  = pd.read_csv(test_csv_path)\n",
        "\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "test_df['filename']  = test_df['id_code'] + '.png'\n",
        "\n",
        "# ----- STEP 3: Split Data into Training and Validation Sets -----\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "val_df['filename']   = val_df['id_code'] + '.png'\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "val_df['diagnosis']   = val_df['diagnosis'].astype(str)\n",
        "\n",
        "# ----- STEP 4: Define Image Size and Create Data Generators -----\n",
        "IMAGE_SIZE = (380, 380)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=10,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='constant',\n",
        "    cval=0\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=train_img_dir,\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    validate_filenames=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=train_img_dir,  # Validation images are assumed to be in the same folder\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# ----- STEP 5: Compute Class Weights for Imbalanced Data -----\n",
        "# Convert diagnosis labels to integers for computing weights.\n",
        "train_labels = train_df['diagnosis'].astype(int).values\n",
        "classes = np.unique(train_labels)\n",
        "class_weights = compute_class_weight('balanced', classes=classes, y=train_labels)\n",
        "class_weight_dict = {int(c): float(w) for c, w in zip(classes, class_weights)}\n",
        "print(\"Computed Class Weights:\", class_weight_dict)\n",
        "\n",
        "# ----- STEP 6: Set Up Callbacks with ModelCheckpoint -----\n",
        "checkpoint_filepath = '/content/drive/My Drive/aptos2019-blindness-detection/best_model.keras'\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    save_weights_only=False\n",
        ")\n",
        "early_stopping_callback = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "callbacks = [checkpoint_callback, reduce_lr, early_stopping_callback]\n",
        "\n",
        "# ----- STEP 7: Build the Model Using EfficientNetB4 with Full Fine-Tuning -----\n",
        "base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "base_model.trainable = True  # Unfreeze all layers for full fine-tuning\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = BatchNormalization()(x)\n",
        "output = Dense(5, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "model.summary()\n",
        "\n",
        "# ----- STEP 8: Compile the Model with a Lower Learning Rate for Fine-Tuning -----\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', AUC(), Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ----- STEP 9: Train the Model (Full Fine-Tuning) with Class Weights -----\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,  # Increase or adjust epochs as needed\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict  # Apply class weights to balance training\n",
        ")\n",
        "\n",
        "# ----- STEP 10: Grad-CAM for Explainability -----\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    max_val = tf.math.reduce_max(heatmap)\n",
        "    if max_val == 0:\n",
        "        heatmap = tf.zeros_like(heatmap)\n",
        "    else:\n",
        "        heatmap = tf.maximum(heatmap, 0) / max_val\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# ----- STEP 11: Demonstrate Grad-CAM on a Sample Image -----\n",
        "sample_img_path = os.path.join(train_img_dir, train_df['filename'].iloc[0])\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img = image.load_img(sample_img_path, target_size=IMAGE_SIZE)\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "last_conv_layer_name = None\n",
        "for layer in base_model.layers[::-1]:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "if last_conv_layer_name is None:\n",
        "    raise ValueError(\"No convolutional layer found in the base model.\")\n",
        "\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "display_gradcam(sample_img_path, heatmap)\n"
      ],
      "metadata": {
        "id": "xSORwGR1RZNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####################################################\n",
        "# Full Script: Load Randomized Model & Fine-Tune on Minimal Preprocessing Data\n",
        "#####################################################\n",
        "\n",
        "# ----- STEP 0: Mount Google Drive -----\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----- STEP 1: Import Libraries and Set Mixed Precision Policy -----\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "\n",
        "# Enable mixed precision for faster training\n",
        "set_global_policy('mixed_float16')\n",
        "\n",
        "# ----- STEP 2: Define Directory Paths and Load CSVs -----\n",
        "train_img_dir = '/content/drive/My Drive/aptos2019-blindness-detection/train_images/'\n",
        "test_img_dir  = '/content/drive/My Drive/aptos2019-blindness-detection/test_images/'\n",
        "train_csv_path = '/content/drive/My Drive/aptos2019-blindness-detection/train.csv'\n",
        "test_csv_path  = '/content/drive/My Drive/aptos2019-blindness-detection/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df  = pd.read_csv(test_csv_path)\n",
        "\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "test_df['filename']  = test_df['id_code'] + '.png'\n",
        "\n",
        "# ----- STEP 3: Split Data into Training and Validation Sets -----\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "train_df['filename'] = train_df['id_code'] + '.png'\n",
        "val_df['filename']   = val_df['id_code'] + '.png'\n",
        "train_df['diagnosis'] = train_df['diagnosis'].astype(str)\n",
        "val_df['diagnosis']   = val_df['diagnosis'].astype(str)\n",
        "\n",
        "# ----- STEP 4: Create Data Generators with Minimal Preprocessing (No Random Augmentation) -----\n",
        "IMAGE_SIZE = (380, 380)\n",
        "\n",
        "# Minimal preprocessing: only rescale images\n",
        "minimal_train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "minimal_val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "minimal_train_generator = minimal_train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory=train_img_dir,\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    validate_filenames=True\n",
        ")\n",
        "\n",
        "minimal_val_generator = minimal_val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    directory=train_img_dir,\n",
        "    x_col='filename',\n",
        "    y_col='diagnosis',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# ----- STEP 5: Compute Class Weights (if needed) -----\n",
        "train_labels = train_df['diagnosis'].astype(int).values\n",
        "classes = np.unique(train_labels)\n",
        "class_weights = compute_class_weight('balanced', classes=classes, y=train_labels)\n",
        "class_weight_dict = {int(c): float(w) for c, w in zip(classes, class_weights)}\n",
        "print(\"Computed Class Weights:\", class_weight_dict)\n",
        "\n",
        "# ----- STEP 6: Load the Previously Trained Model -----\n",
        "# This model was trained with heavy random augmentation\n",
        "model = load_model('/content/drive/My Drive/aptos2019-blindness-detection/best_model.keras')\n",
        "print(\"Model loaded from checkpoint.\")\n",
        "\n",
        "# ----- STEP 7: Re-Compile the Model for Fine-Tuning -----\n",
        "# Here we use a lower learning rate for fine-tuning on minimal preprocessing data.\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', AUC(), Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ----- STEP 8: Set Up Callbacks (Optional: Update filepath if desired) -----\n",
        "checkpoint_filepath = '/content/drive/My Drive/aptos2019-blindness-detection/best_model_minimal.keras'\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        "    save_weights_only=False\n",
        ")\n",
        "early_stopping_callback = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "callbacks = [checkpoint_callback, reduce_lr, early_stopping_callback]\n",
        "\n",
        "# ----- STEP 9: Fine-Tune the Model on Minimal Preprocessing Data -----\n",
        "history_minimal = model.fit(\n",
        "    minimal_train_generator,\n",
        "    epochs=20,  # Adjust epochs as needed\n",
        "    validation_data=minimal_val_generator,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict  # Use class weights to balance the training if needed\n",
        ")\n",
        "\n",
        "# ----- STEP 10: (Optional) Grad-CAM for Explainability -----\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    max_val = tf.math.reduce_max(heatmap)\n",
        "    if max_val == 0:\n",
        "        heatmap = tf.zeros_like(heatmap)\n",
        "    else:\n",
        "        heatmap = tf.maximum(heatmap, 0) / max_val\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Demonstrate Grad-CAM on a Sample Image\n",
        "sample_img_path = os.path.join(train_img_dir, train_df['filename'].iloc[0])\n",
        "img = image.load_img(sample_img_path, target_size=IMAGE_SIZE)\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "last_conv_layer_name = None\n",
        "for layer in model.layers[::-1]:\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "if last_conv_layer_name is None:\n",
        "    raise ValueError(\"No convolutional layer found in the model.\")\n",
        "\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "display_gradcam(sample_img_path, heatmap)\n"
      ],
      "metadata": {
        "id": "Fot70IwIleDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}